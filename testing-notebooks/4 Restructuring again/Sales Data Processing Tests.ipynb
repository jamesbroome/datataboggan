{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run \"4 Restructuring again/Sales Data Processing 4\" { test_mode: true }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "orders_schema = [\"OrderId\",\"OrderDate\", \"Region\", \"City\", \"Category\",\"Product\",\"Quantity\",\"UnitPrice\",\"TotalPrice\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def test_orders_with_duplicated_order_id_are_removed():\r\n",
        "    \r\n",
        "    # Arrange\r\n",
        "    df = spark.createDataFrame(\r\n",
        "            [\r\n",
        "                (10,\"01/01/2020\",\"North\",\"Chicago\",\"Bars\",\"Carrot\",33,1.77,58.41),\r\n",
        "                (10,\"11/03/2020\",\"North\",\"Chicago\",\"Bars\",\"Carrot\",33,1.77,58.41),\r\n",
        "            ],\r\n",
        "            orders_schema \r\n",
        "        )\r\n",
        "\r\n",
        "    #Act\r\n",
        "    df_result = remove_duplicate_orders(df)\r\n",
        "\r\n",
        "    #Assert\r\n",
        "    assert df_result, \"No data frame returned from remove_duplicate_orders()\"\r\n",
        "\r\n",
        "    expected_orders = 1\r\n",
        "    number_of_orders = df_result.count()\r\n",
        "    assert number_of_orders == 1, f'Expected {expected_orders} order after remove_duplicate_orders() but {number_of_orders} returned.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def test_similar_orders_with_different_order_id_are_not_removed():\r\n",
        "    \r\n",
        "    # Arrange\r\n",
        "    df = spark.createDataFrame(\r\n",
        "            [\r\n",
        "                (10,\"01/01/2020\",\"North\",\"Chicago\",\"Bars\",\"Carrot\",33,1.77,58.41),\r\n",
        "                (11,\"01/01/2020\",\"North\",\"Chicago\",\"Bars\",\"Carrot\",33,1.77,58.41),\r\n",
        "                (12,\"01/01/2020\",\"North\",\"Chicago\",\"Bars\",\"Carrot\",33,1.77,58.41),\r\n",
        "            ],\r\n",
        "            orders_schema \r\n",
        "        )\r\n",
        "\r\n",
        "    #Act\r\n",
        "    df_result = remove_duplicate_orders(df)\r\n",
        "\r\n",
        "    #Assert\r\n",
        "    expected_orders = 3\r\n",
        "    number_of_orders = df_result.count()\r\n",
        "    assert number_of_orders == 3, f'Expected {expected_orders} order after remove_duplicate_orders() but {number_of_orders} returned.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def test_regional_sales_are_calculated_correctly():\r\n",
        "\r\n",
        "    # Arrange\r\n",
        "    df = spark.createDataFrame(\r\n",
        "            [\r\n",
        "                (7,\"19/01/2020\",\"East\",\"Boston\",\"Crackers\",\"Whole Wheat\",149,3.49,520.01),\r\n",
        "                (8,\"22/01/2020\",\"West\",\"Los Angeles\",\"Bars\",\"Carrot\",51,1.77,90.27),\r\n",
        "                (9,\"25/01/2020\",\"East\",\"New York\",\"Bars\",\"Carrot\",100,1.77,177.00),\r\n",
        "                (10,\"28/01/2020\",\"East\",\"New York\",\"Snacks\",\"Potato Chips\",28,1.35,37.8),\r\n",
        "            ],\r\n",
        "            orders_schema \r\n",
        "        )\r\n",
        "        \r\n",
        "    #Act\r\n",
        "    df_result = calculate_sales_by_region(df)\r\n",
        "\r\n",
        "    #Assert\r\n",
        "    expected_sales_east = 734.81\r\n",
        "    sales_east = df_result.where(df_result[\"Region\"] == \"East\").collect()[0][\"TotalSales\"]\r\n",
        "\r\n",
        "    assert expected_sales_east == sales_east, f'Expected regional sales to be {expected_sales_east} for East region but {sales_east} returned.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "test_orders_with_duplicated_order_id_are_removed()\r\n",
        "test_similar_orders_with_different_order_id_are_not_removed()\r\n",
        "test_regional_sales_are_calculated_correctly()"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}