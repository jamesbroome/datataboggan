{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    df_orders = spark.read.csv('abfss://<container>@<account-name>.dfs.core.windows.net/<path>/orders.csv', header='true', inferSchema='true')\n",
        "    return df_orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def remove_duplicate_orders(df):\n",
        "    return df.distinct()\n",
        "    #return df.dropDuplicates([\"OrderId\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def calculate_sales_by_region(df):\n",
        "    return df \\\n",
        "        .select(\"Region\", \"TotalPrice\") \\\n",
        "        .groupBy(\"Region\") \\\n",
        "        .sum(\"TotalPrice\") \\\n",
        "        .withColumnRenamed(\"sum(TotalPrice)\", \"TotalSales\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def save_output(df):\n",
        "    df.repartition(1) \\\n",
        "        .write.mode(\"overwrite\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .csv('abfss://<container>@<account-name>.dfs.core.windows.net/<path>/output/')\n",
        "\n",
        "    df.show()"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
