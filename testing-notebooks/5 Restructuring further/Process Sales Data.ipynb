{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Process Sales Data workflow\r\n",
        "\r\n",
        "This process is pretty straightforward as it's purely for demo purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "%run \"5 Restructuring further/Sales Data Functions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load the raw data from the lake\r\n",
        "df_orders = load_data()\r\n",
        "\r\n",
        "# De-dup\r\n",
        "df_unique_orders = remove_duplicate_orders(df_orders)\r\n",
        "\r\n",
        "# Aggregate sales by region\r\n",
        "df_sales_by_region = calculate_sales_by_region(df_unique_orders)\r\n",
        "\r\n",
        "# Write back to the lake for reporting\r\n",
        "save_output(df_sales_by_region)"
      ]
    }
  ]
}